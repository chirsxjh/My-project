## 监督学习

### 有监督学习

是机器学习任务的一种。它从有标记的训练数据中推导出预测函数。有标记的训练数据是指每个训练实例都包括输入和期望的输出。一句话：给定数据，预测标签。

#### 举例

有监督学习：学认字

#### 特点

有标签

直接反馈

预测未来结果

### 无监督学习

是机器学习任务的一种。它从无标记的训练数据中推断结论。最典型的无监督学习就是聚类分析，它可以在探索性数据分析阶段用于发现隐藏的模式或者对数据进行分组。一句话：给定数据，寻找隐藏的结构。

#### 举例

无监督学习：自动聚类

#### 特点

无标签

无反馈

寻找隐藏的结构

### 强化学习

是机器学习的另一个领域。它关注的是软件代理如何在一个环境中采取行动以便最大化某种累积的回报。一句话：给定数据，学习如何选择一系列行动，以最大化长期收益。

例如学英语。有监督学习是先读几篇中英文对照的文章，从而学会阅读纯英语文章。无监督学习是直接阅读大量纯英文文章，当数量达到一定程度，虽然不能完全理解文章，但也会发现一些词组的固定搭配，句式等等。

#### 举例

增强学习：学下棋

#### 特点

决策流程

激励系统

学习一系列的行动

### 区别

看是否有监督（supervised），就看输入数据是否有标签（label）。输入数据有标签，则为有监督学习，没标签则为无监督学习。

首先看什么是学习（learning）？一个成语就可概括：举一反三。此处以高考为例，高考的题目在上考场前我们未必做过，但在高中三年我们做过很多很多题目，懂解题方法，因此考场上面对陌生问题也可以算出答案。机器学习的思路也类似：我们能不能利用一些训练数据（已经做过的题），使机器能够利用它们（解题方法）分析未知数据（高考的题目）？**最简单也最普遍的一类机器学习算法就是分类（classification）**。对于分类，输入的训练数据``有特征（feature）``，``有标签（label）``。所谓的学习，其本质就是找到特征和标签间的关系（mapping）。这样当有特征而无标签的未知数据输入时，我们就可以通过已有的关系得到未知数据标签。在上述的分类过程中，如果所有训练数据都有标签，则为有监督学习（supervised learning）。**如果数据没有标签，显然就是无监督学习（unsupervised learning）了，也即聚类（clustering）**。目前分类算法的效果还是不错的，但相对来讲，聚类算法就有些惨不忍睹了。确实，无监督学习本身的特点使其难以得到如分类一样近乎完美的结果。这也正如我们在高中做题，答案（标签）是非常重要的，假设两个完全相同的人进入高中，一个正常学习，另一人做的所有题目都没有答案，那么想必第一个人高考会发挥更好，第二个人会发疯。这时各位可能要问，既然分类如此之好，聚类如此之不靠谱，那为何我们还可以容忍聚类的存在？因为在实际应用中，标签的获取常常需要极大的人工工作量，有时甚至非常困难。例如在自然语言处理（NLP）中，Penn Chinese Treebank在2年里只完成了4000句话的标签…![png](https://pic1.zhimg.com/4b92820e4df9ab2ed4d56243d981cdcc_b.jpg)

时有人可能会想，难道有监督学习和无监督学习就是非黑即白的关系吗？有没有灰呢？Good idea。灰是存在的。二者的中间带就是半监督学习（semi-supervised learning）。对于半监督学习，其训练数据的一部分是有标签的，另一部分没有标签，而没标签数据的数量常常极大于有标签数据数量（这也是符合现实情况的）。隐藏在半监督学习下的基本规律在于：数据的分布必然不是完全随机的，通过一些有标签数据的局部特征，以及更多没标签数据的整体分布，就可以得到可以接受甚至是非常好的分类结果。（此处大量忽略细节）因此，learning家族的整体构造是这样的：有监督学习（分类，回归）↕半监督学习（分类，回归），transductive learning（分类，回归）↕半监督聚类（有标签数据的标签不是确定的，类似于：肯定不是xxx，很可能是yyy）↕无监督学习（聚类）